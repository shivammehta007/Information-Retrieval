{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Spell Checker\n#### Edit 1: Stupid Naive approach (Code deleted, it was just looping over everything maybe will take one year to solve this problem)\n#### Edit 2: Peter Norvich's spell checker\n#### Edit 3: Added Trie"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n# Required Distance\n!pip install textdistance","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/itmo-spelling-correction-autumn-2019/evaluate.py\n/kaggle/input/itmo-spelling-correction-autumn-2019/no_fix.submission.csv\n/kaggle/input/itmo-spelling-correction-autumn-2019/words.csv\n/kaggle/input/itmo-spelling-correction-autumn-2019/train.csv\nCollecting textdistance\n  Downloading https://files.pythonhosted.org/packages/3f/18/31397b687f50ffae65469175f07faa68f288e27fcd8716276004c42e5637/textdistance-4.1.5-py3-none-any.whl\nInstalling collected packages: textdistance\nSuccessfully installed textdistance-4.1.5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import textdistance\nimport time\nimport csv\nimport tqdm\nimport operator\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_file = '/kaggle/input/itmo-spelling-correction-autumn-2019/words.csv'\ntrain_file = '/kaggle/input/itmo-spelling-correction-autumn-2019/no_fix.submission.csv'\ntruth_file = '/kaggle/input/itmo-spelling-correction-autumn-2019/train.csv'","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Word Dict\nwords = {}\n\nwith open(word_file, newline='') as file:\n    buffer = csv.DictReader(file)\n    for r in tqdm.tqdm(buffer):\n        words[r['Id']] = int(r['Freq'])","execution_count":4,"outputs":[{"output_type":"stream","text":"724512it [00:05, 126024.71it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Truth File\ntruth_values = set()\n\nwith open(truth_file, newline='') as file:\n    buffer = csv.DictReader(file)\n    for r in tqdm.tqdm(buffer):\n        truth_values.add(r['Expected'])\n","execution_count":15,"outputs":[{"output_type":"stream","text":"362256it [00:02, 139290.41it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(truth_values)","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"332090"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"distance_to_keep = [1, 2]\ndistance_function = textdistance.levenshtein","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WORDS = words\n\ndef correction(initial_word, threshold=1000):\n    \"Most probable spelling correction for word.\"\n    probability_dict = {}\n    # Probability for just the word\n    for word in known([initial_word]):\n        if word in WORDS:\n            if WORDS[word] > threshold:\n                probability_dict[word] = WORDS[word]\n        \n    \n    # Probability for one edit\n    for word in known(edits1(initial_word)):\n        if word in WORDS:\n            if WORDS[word] > threshold:\n                probability_dict[word] = WORDS[word]\n    \n#     # Probability for two edits\n#     for word in known(edits2(word)):\n#         probability_dict[word] = WORDS[word]\n#     print(f'Prob dictionary: {probability_dict}')\n\n    if probability_dict:\n        correction = sorted(probability_dict.items(), key=operator.itemgetter(1), reverse=True)[0][0]\n    else:\n        correction = initial_word\n\n    return correction\n\n\ndef known(words):\n    \"The subset of `words` that appear in the dictionary of WORDS.\"\n    if words:\n        return set(w for w in words if w and w in truth_values)\n    return set()\n\n        \n\ndef edits1(word):\n    \"All edits that are one edit away from `word`.\"\n    letters    = 'бвгджзклмнпрстфхцчшщаэыуояеёюийьъabcdefghijklmnopqrstuvwxyz'.upper()\n    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n    deletes    = [L + R[1:]               for L, R in splits if R]\n    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n    inserts    = [L + c + R               for L, R in splits for c in letters]\n    return set(deletes + transposes + replaces + inserts)\n\ndef edits2(word): \n    \"All edits that are two edits away from `word`.\"\n    return (e2 for e1 in edits1(word) for e2 in edits1(e1))","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correction('АНІМЕ')","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"'АНИМЕ'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"correction('UNIZOOI')","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"'UNIZOOI'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Testing This"},{"metadata":{},"cell_type":"markdown","source":"It works lets try on all test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = []\nwith open(train_file) as file:\n    buffer = csv.DictReader(file)\n    for r in tqdm.tqdm(buffer):\n        train.append(r['Id'])","execution_count":41,"outputs":[{"output_type":"stream","text":"362256it [00:02, 145386.63it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('submission_pn.csv', 'w', newline='') as file:\n    buffer = csv.writer(file)\n    buffer.writerow(['Id', 'Predicted'])\n    for word in tqdm.tqdm(train):\n        corr = correction(word, 4000)\n        buffer.writerow([word, corr])","execution_count":44,"outputs":[{"output_type":"stream","text":"100%|██████████| 362256/362256 [03:56<00:00, 1529.04it/s]\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"# **Trie**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Trie:\n    \"\"\"\n    Trie\n\n    Trie is a treelike datastructure used to predict suggestion here is a\n    simple implementation of it with add and search functionality.\n\n    It has a root that is the head or the Trie and a node_count to count\n    total number of nodes currently in Trie\n    \"\"\"\n\n    class _Node:\n        \"\"\"\n        Node\n\n        This is how a trie node looks like it has a hashmap of characters\n        with an end indicating weather this is the end of word or not.\n        One additional field that I added is the frequency count just for\n        furthur probabilistic calculations if required.\n        \"\"\"\n\n        def __init__(self, end=False):\n            self.characters = {}\n            self.frequency = 0\n            self.end = end\n\n    def __init__(self):\n        self.root = self._Node()\n        self.node_count = 1\n\n\n    def add_string(self, string):\n        \"\"\"\n        Adds a string to the trie\n        Parameters:\n        string: String\n        \"\"\"\n        node = self.root\n        for c in string:\n            if c not in node.characters:\n                node.characters[c] = self._Node()\n                self.node_count += 1\n\n            node = node.characters[c]\n\n        node.end = True\n        if string in WORDS:\n            node.frequency = WORDS[string]\n\n    def search_word(self, string):\n        \"\"\"\n        Searches for a word in the trie\n        Parameters:\n        string: String\n        \"\"\"\n        node = self.root\n        for c in string:\n            if c not in node.characters:\n                return False, 0\n            node = node.characters[c]\n\n        if node.end:\n            return True, node.frequency\n\n        return False, 0\n\n    def one_edit_distance(self, word):\n        \"\"\"\n        All edits that are one edit away from word\n        Parameters:\n        word: String\n        \"\"\"\n        \n        letters    = 'бвгджзклмнпрстфхцчшщаэыуояеёюийьъabcdefghijklmnopqrstuvwxyz'.upper()\n        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n        deletes    = [L + R[1:]               for L, R in splits if R]\n        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n        inserts    = [L + c + R               for L, R in splits for c in letters]\n        return set(deletes + transposes + replaces + inserts)\n    \n    \n    def correct_spelling(self, initial_word, threshold=1000):\n        \"\"\"\n        Checks and Returns the Correct Spelling of the Word with one edit distance\n        \"\"\"\n        probability_dict = {}\n        present, _ = self.search_word(initial_word)\n        if present:\n            return initial_word\n    \n        for word in self.one_edit_distance(initial_word):\n            present, freq = self.search_word(word)\n            if not present:\n                continue\n            probability_dict[word] = freq\n            \n\n        if probability_dict:\n            correction = sorted(probability_dict.items(), key=operator.itemgetter(1), reverse=True)[0][0]\n        else:\n            correction = initial_word\n        \n        return correction\n  ","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trie = Trie()","execution_count":77,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for word in tqdm.tqdm(truth_values):\n    trie.add_string(word)","execution_count":78,"outputs":[{"output_type":"stream","text":"100%|██████████| 332090/332090 [00:13<00:00, 24794.82it/s]\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"#### Some Tests"},{"metadata":{"trusted":true},"cell_type":"code","source":"trie.search_word('АНИМЕ')","execution_count":79,"outputs":[{"output_type":"execute_result","execution_count":79,"data":{"text/plain":"(True, 314178)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trie.correct_spelling('КИТАЦ') # КИТАЙ","execution_count":104,"outputs":[{"output_type":"execute_result","execution_count":104,"data":{"text/plain":"'КИТАЙ'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Lets Create the final Submission "},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('submission_trie.csv', 'w', newline='') as file:\n    buffer = csv.writer(file)\n    buffer.writerow(['Id', 'Predicted'])\n    for word in tqdm.tqdm(train):\n        corr = trie.correct_spelling(word)\n        buffer.writerow([word, corr])","execution_count":82,"outputs":[{"output_type":"stream","text":"100%|██████████| 362256/362256 [15:42<00:00, 384.37it/s] \n","name":"stderr"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}