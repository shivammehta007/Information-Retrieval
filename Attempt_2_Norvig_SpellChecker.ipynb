{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very Naïve and Time Consuming Solution, we need to improve this with Trie\n",
    "#### Edit 1: Stupid Naive approach (Code deleted, it was just looping over everything maybe will take one year to solve this problem)\n",
    "#### Edit 2: Peter Norvich's spell checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/itmo-spelling-correction-autumn-2019/evaluate.py\n",
      "/kaggle/input/itmo-spelling-correction-autumn-2019/no_fix.submission.csv\n",
      "/kaggle/input/itmo-spelling-correction-autumn-2019/words.csv\n",
      "/kaggle/input/itmo-spelling-correction-autumn-2019/train.csv\n",
      "Collecting textdistance\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/18/31397b687f50ffae65469175f07faa68f288e27fcd8716276004c42e5637/textdistance-4.1.5-py3-none-any.whl\n",
      "Installing collected packages: textdistance\n",
      "Successfully installed textdistance-4.1.5\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "# Required Distance\n",
    "!pip install textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "import time\n",
    "import csv\n",
    "import tqdm\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_file = '/kaggle/input/itmo-spelling-correction-autumn-2019/words.csv'\n",
    "train_file = '/kaggle/input/itmo-spelling-correction-autumn-2019/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "724512it [00:05, 131197.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load Word Dict\n",
    "words = {}\n",
    "\n",
    "with open(word_file, newline='') as file:\n",
    "    buffer = csv.DictReader(file)\n",
    "    for r in tqdm.tqdm(buffer):\n",
    "        words[r['Id']] = int(r['Freq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_keep = [1, 2]\n",
    "distance_function = textdistance.levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORDS = words\n",
    "\n",
    "# def correction(word):\n",
    "#     \"Most probable spelling correction for word.\"\n",
    "#     probability_dict = {}\n",
    "#     # Probability for just the word\n",
    "#     for word in known([word]):\n",
    "#         probability_dict[word] = WORDS[word]\n",
    "    \n",
    "#     # Probability for one edit\n",
    "#     for word in known(edits1(word)):\n",
    "#         probability_dict[word] = WORDS[word]\n",
    "    \n",
    "# #     # Probability for two edits\n",
    "# #     for word in known(edits2(word)):\n",
    "# #         probability_dict[word] = WORDS[word]\n",
    "        \n",
    "#     if probability_dict:\n",
    "#         correction = sorted(probability_dict.items(), key=operator.itemgetter(1), reverse=True)[0][0]\n",
    "#     else:\n",
    "#         correction = word\n",
    "#     return correction\n",
    "\n",
    "\n",
    "# def known(words):\n",
    "#     \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "#     if words:\n",
    "#         return set(w for w in words if w and w in WORDS)\n",
    "#     return set()\n",
    "\n",
    "        \n",
    "\n",
    "# def edits1(word):\n",
    "#     \"All edits that are one edit away from `word`.\"\n",
    "#     letters    = 'бвгджзклмнпрстфхцчшщаэыуояеёюийьъabcdefghijklmnopqrstuvwxyz'.upper()\n",
    "#     splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "#     deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "#     transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "#     replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "#     inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "#     return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "# def edits2(word): \n",
    "#     \"All edits that are two edits away from `word`.\"\n",
    "#     return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = words\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word):\n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]).union(known(edits1(word)) or [word]))\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    if words:\n",
    "        return set(w for w in words if w and w in WORDS)\n",
    "    return set()\n",
    "\n",
    "        \n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'бвгджзклмнпрстфхцчшщаэыуояеёюийьъabcdefghijklmnopqrstuvwxyz'.upper()\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNIZOO'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('UNIZOOI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ПОРНОСПЯЩИЕ\n",
      "--- 0.0021860599517822266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(correction('ПОРНОСПЯЩИЕA'))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works lets try on all test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "362256it [00:02, 146554.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "with open(train_file) as file:\n",
    "    buffer = csv.DictReader(file)\n",
    "    for r in tqdm.tqdm(buffer):\n",
    "        train.append(r['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 362256/362256 [04:14<00:00, 1422.39it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('submission.csv', 'w', newline='') as file:\n",
    "    buffer = csv.writer(file)\n",
    "    buffer.writerow(['Id', 'Predicted'])\n",
    "    for word in tqdm.tqdm(train):\n",
    "        corr = correction(word)\n",
    "        buffer.writerow([word, corr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>НЕЛОВКО</td>\n",
       "      <td>НЕЛОВКО</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNIZOOI</td>\n",
       "      <td>UNIZOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC</td>\n",
       "      <td>ISI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DUNYADA</td>\n",
       "      <td>DUNYAYA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ITALWAX</td>\n",
       "      <td>ITALWAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362251</th>\n",
       "      <td>ПИТЕРТУР</td>\n",
       "      <td>ПИТЕРТУР</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362252</th>\n",
       "      <td>СПИНОЙ1</td>\n",
       "      <td>СПИНОЙ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362253</th>\n",
       "      <td>СПОСОБИН</td>\n",
       "      <td>СПОСОБЕН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362254</th>\n",
       "      <td>СТАРШЕКЛАССНИЦА</td>\n",
       "      <td>СТАРШЕКЛАССНИЦА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362255</th>\n",
       "      <td>ПРИМКРАБ</td>\n",
       "      <td>ПРИМКРАБ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Id        Predicted\n",
       "0               НЕЛОВКО          НЕЛОВКО\n",
       "1               UNIZOOI           UNIZOO\n",
       "2                  ISIC              ISI\n",
       "3               DUNYADA          DUNYAYA\n",
       "4               ITALWAX          ITALWAX\n",
       "...                 ...              ...\n",
       "362251         ПИТЕРТУР         ПИТЕРТУР\n",
       "362252          СПИНОЙ1           СПИНОЙ\n",
       "362253         СПОСОБИН         СПОСОБЕН\n",
       "362254  СТАРШЕКЛАССНИЦА  СТАРШЕКЛАССНИЦА\n",
       "362255         ПРИМКРАБ         ПРИМКРАБ\n",
       "\n",
       "[362256 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
