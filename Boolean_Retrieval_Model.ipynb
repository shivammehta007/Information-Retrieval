{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shivammehta007/Information-Retrieval/blob/master/Boolean_Retrieval_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WcDgh8T8ssDl"
   },
   "source": [
    "# Boolean Retrieval Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kt1iyTAetJEn"
   },
   "source": [
    "## Library Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "6m3-c0xbtIaV",
    "outputId": "f27a3392-3e00-4806-88cc-78e7de99e9ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.0)\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# !pip install pymorphy2\n",
    "!pip install tqdm -U\n",
    "import os\n",
    "import gzip\n",
    "import nltk\n",
    "import pickle\n",
    "import logging\n",
    "import itertools\n",
    "import re\n",
    "# import pymorphy2\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "logger = logging.getLogger('ir')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xGw6jtM1swxL"
   },
   "source": [
    "## Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TFdsGQmgs1Y3",
    "outputId": "69b2608b-8fe2-47da-b067-70cb40e1514d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlE9fk4TtFMT"
   },
   "outputs": [],
   "source": [
    "indexing_data_location = '/content/drive/My Drive/Homeworks/InformationRetrieval/hw1_docs.tsv.gz'\n",
    "query_validate = '/content/drive/My Drive/Homeworks/InformationRetrieval/hw1_queries_validate.tsv'\n",
    "truedoc_validate = '/content/drive/My Drive/Homeworks/InformationRetrieval/hw1_truedocs_validate.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRtfzR_0IfHx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "32CwuYhBUpX2"
   },
   "source": [
    "### Testing Block Skip If you are evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "jEQ4C7xG5zfD",
    "outputId": "42d348ba-dd8e-4527-f0a4-dd39a6fd8b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFFICE HOURS SATURDAY THURSDAY 8 AM 5 PM CONSULAR SECTION TUESDAY THURSDAY AND SUNDAY 9 AM 1 PM EMERGENCY ASSISTANCE ADDRESS STREET 3 COMMUNITY 314 UMM HURAIR FIRST BUR DUBAI A DUBAI UAE MAKANI NUMBER 29820 94373 TEL 9714 370 60 60 FAX 9714 370 60 63 E MAIL UZBEKCONSULATE AE MAIL RU P O BOX 50478 LOCATION MAP CONSULATE GENERAL OF THE REPUBLIC OF UZBEKISTAN IN DUBAI UAE PROFILE OF UZBEKISTAN STATE SYMBOLS CONSTITUTION PRESIDENT HISTORY PEOPLE CULTURE ECOLOGY NATIONAL HOLIDAYS ECONOMY DEVELOPMENT OF INTERNATIONAL RELATIONS TRAVELING TO UZBEKISTAN INVITATION TO UZBEKISTAN TOURISM IN UZBEKISTAN HISTORICAL PLACES TOUR COMPANIES HOTELS IN UZBEKISTAN BUSINESS IN UZBEKISTAN WHY UZBEKISTAN INVESTMENT GUIDE INVESTMENT OPPORTUNITIES INVESTMENT PROJECTS MULTIME S VIDEO AUDIO PHOTO HOME CONSULAR SERVICE O ZBEK русск IN ENGLISH BILETARIAL RELATION PRESS RELEASES EVENTS CONTACT US USEFUL LINKS 25 TH ANNIVERSARY OF INDEPENDENCE OF UZBEKISTAN легк промышлен узбекиста укрепля расширя позиц миров рынк 7 миллион доллар бол 1 миллиард доллар сравн эт цифр почувствова разниц перв цифр показыва обь экспорт текстильн швейн трикотажн продукц отечествен предприят 1994 год втор характериз показател 2015 год можн полн уверен сказа год независим легк промышлен узбекиста тольк уверен вышл внешн рынок заня нем прочн позиц продолж активн наращива экспортн потенциа лучш поня достоинств оцен ту грандиозн работ котор провед руководств республик труженик отрасл дан направлен вспомн положен существова легк промышлен узбекиста начал 90 х год прошл век те врем довел присутствова встреч наш специалист зарубежн коллег приеха наш стран интересова ситуац ряд отрасл числ легк промышлен точн производств текстильн продукц никак могл поня поч узбекистан выращива стольк хлопк практическ собствен ткан готов одежд рынк люд предлага импортн товар прич сомнительн качеств вопрос поч чащ всег звуча зал например поч республик занима основн тольк получен волокн хлопк сырц ил поч общ количеств выработа волокн пряж ткан перерабатыва всег лиш 10 процент поч экспорт отправля тольк хлопков волокн готов издел бол высок добавлен стоимост горазд прибыльн поч отправл выращен нелегк труд хлопок предел республик хлопкороб зат вынужд покупа рубашк узбекск хлопк горазд больш цен подобн вопрос нема отда должн наш специалист пыта ответ вопрос говор бывш союз узбекистан отвод рол основн производител хлопк сырц поставщик хлопков волокн дальн переработк друг республик оборудован используем немногочислен текстильн предприят моральн устаревш физическ изношен позволя внедря нов технолог выпуска конкурентоспособн продукц вопрос экспорт занима центр котор определя скольк стран отправля республик напрям экспорт хлопков волокн доход получа можн посочувствова специалист частност хорош известн располаг хорош сырьев баз выгодн развива текстильн производств производств пряж ткан приход окол 80 процент добавлен стоимост конечн товарн продукц тогд производств хлопк волокн окол 10 процент ест стран экспортер пряж ткан получа доход восем превыша доход экспорт хлопков волокн есл экспортирова готов одежд доход вырастут ещ больш те врем тех услов определен бывш командн административн систем решен принима мест союзн республик называ центр ситуац кардинальн измен посл обретен узбекистан независим разработк нача реализац целенаправлен системн государствен промышлен политик нацелен диверсификац модернизац повышен конкурентоспособн отечествен экономик поддержк развит ведущ отрасл числ наращиван экспортн потенциа счет углублен переработк местн сыр последовательн планомерн переориентац экспорт сыр готов продукц высок добавлен стоимост позвол сформирова нов стратег развит легк промышлен нацелен перспектив мощн импульс нов этап развит отрасл прида принят разн год руководств республик программн\n"
     ]
    }
   ],
   "source": [
    "test_sen = 'OFFICE HOURS SATURDAY THURSDAY 8 AM 5 PM CONSULAR SECTION TUESDAY THURSDAY AND SUNDAY 9 AM 1 PM EMERGENCY ASSISTANCE ADDRESS STREET 3 COMMUNITY 314 UMM HURAIR FIRST BUR DUBAI AREA DUBAI UAE MAKANI NUMBER 29820 94373 TEL 9714 370 60 60 FAX 9714 370 60 63 E MAIL UZBEKCONSULATE AE MAIL RU P O BOX 50478 LOCATION MAP CONSULATE GENERAL OF THE REPUBLIC OF UZBEKISTAN IN DUBAI UAE PROFILE OF UZBEKISTAN STATE SYMBOLS CONSTITUTION PRESIDENT HISTORY PEOPLE CULTURE ECOLOGY NATIONAL HOLIDAYS ECONOMY DEVELOPMENT OF INTERNATIONAL RELATIONS TRAVELING TO UZBEKISTAN INVITATION TO UZBEKISTAN TOURISM IN UZBEKISTAN HISTORICAL PLACES TOUR COMPANIES HOTELS IN UZBEKISTAN BUSINESS IN UZBEKISTAN WHY UZBEKISTAN INVESTMENT GUIDE INVESTMENT OPPORTUNITIES INVESTMENT PROJECTS MULTIMEDIA S VIDEO AUDIO PHOTO HOME CONSULAR SERVICE O ZBEKCHA НА РУССКОМ IN ENGLISH BILETARIAL RELATION PRESS RELEASES EVENTS CONTACT US USEFUL LINKS 25 TH ANNIVERSARY OF INDEPENDENCE OF UZBEKISTAN ЛЕГКАЯ ПРОМЫШЛЕННОСТЬ УЗБЕКИСТАНА УКРЕПЛЯТЬ И РАСШИРЯТЬ ПОЗИЦИИ НА МИРОВОМ РЫНКЕ 7 МИЛЛИОНОВ ДОЛЛАРОВ И БОЛЕЕ 1 МИЛЛИАРДА ДОЛЛАРОВ СРАВНИТЕ ЭТИ ЦИФРЫ ПОЧУВСТВОВАЛИ РАЗНИЦУ А ТАК КАК ПЕРВАЯ ЦИФРА ПОКАЗЫВАЕТ ОБЪЕМ ЭКСПОРТА ТЕКСТИЛЬНОЙ И ШВЕЙНО ТРИКОТАЖНОЙ ПРОДУКЦИИ ОТЕЧЕСТВЕННЫХ ПРЕДПРИЯТИЙ В 1994 ГОДУ А ВТОРАЯ ХАРАКТЕРИЗУЕТ ТОТ ЖЕ ПОКАЗАТЕЛЬ НО УЖЕ ЗА 2015 ГОД ТО МОЖНО С ПОЛНОЙ УВЕРЕННОСТЬЮ СКАЗАТЬ ЧТО ЗА ГОДЫ НЕЗАВИСИМОСТИ ЛЕГКАЯ ПРОМЫШЛЕННОСТЬ УЗБЕКИСТАНА НЕ ТОЛЬКО УВЕРЕННО ВЫШЛА НА ВНЕШНИЙ РЫНОК НО И ЗАНЯЛА НА НЕМ ПРОЧНЫЕ ПОЗИЦИИ ПРОДОЛЖАЯ АКТИВНО НАРАЩИВАТЬ ЭКСПОРТНЫЙ ПОТЕНЦИАЛ ЧТОБЫ ЛУЧШЕ ПОНЯТЬ И ПО ДОСТОИНСТВУ ОЦЕНИТЬ ТУ ГРАНДИОЗНУЮ РАБОТУ КОТОРАЯ БЫЛА ПРОВЕДЕНА РУКОВОДСТВОМ РЕСПУБЛИКИ И ТРУЖЕНИКАМИ ОТРАСЛИ В ДАННОМ НАПРАВЛЕНИИ НАДО ВСПОМНИТЬ ПОЛОЖЕНИЕ СУЩЕСТВОВАВШЕЕ В ЛЕГКОЙ ПРОМЫШЛЕННОСТИ УЗБЕКИСТАНА В НАЧАЛЕ 90 Х ГОДОВ ПРОШЛОГО ВЕКА КАК ТО В ТЕ ВРЕМЕНА ДОВЕЛОСЬ ПРИСУТСТВОВАТЬ НА ВСТРЕЧЕ НАШИХ СПЕЦИАЛИСТОВ С ЗАРУБЕЖНЫМИ КОЛЛЕГАМИ ПРИЕХАВШИМИ В НАШУ СТРАНУ И ИНТЕРЕСОВАВШИМИСЯ КАК РАЗ СИТУАЦИЕЙ В РЯДЕ ОТРАСЛЕЙ В ТОМ ЧИСЛЕ В ЛЕГКОЙ ПРОМЫШЛЕННОСТИ А ТОЧНЕЕ ПРОИЗВОДСТВОМ ТЕКСТИЛЬНОЙ ПРОДУКЦИИ ОНИ НИКАК НЕ МОГЛИ ПОНЯТЬ ПОЧЕМУ В УЗБЕКИСТАНЕ ГДЕ ВЫРАЩИВАЕТСЯ СТОЛЬКО ХЛОПКА ПРАКТИЧЕСКИ НЕТ СОБСТВЕННЫХ ТКАНЕЙ ГОТОВОЙ ОДЕЖДЫ А НА РЫНКАХ ЛЮДЯМ ПРЕДЛАГАЮТ ИМПОРТНЫЙ ТОВАР ПРИЧЕМ СОМНИТЕЛЬНОГО КАЧЕСТВА ЭТОТ ВОПРОС ПОЧЕМУ ЧАЩЕ ВСЕГО ЗВУЧАЛ В ЗАЛЕ НАПРИМЕР ПОЧЕМУ В РЕСПУБЛИКЕ ЗАНИМАЮТСЯ В ОСНОВНОМ ТОЛЬКО ПОЛУЧЕНИЕМ ВОЛОКНА ИЗ ХЛОПКА СЫРЦА ИЛИ ПОЧЕМУ ИЗ ОБЩЕГО КОЛИЧЕСТВА ВЫРАБОТАННОГО ВОЛОКНА В ПРЯЖУ И ТКАНИ ПЕРЕРАБАТЫВАЕТСЯ ВСЕГО ЛИШЬ 10 ПРОЦЕНТОВ ПОЧЕМУ НА ЭКСПОРТ ОТПРАВЛЯЕТСЯ ТОЛЬКО ХЛОПКОВОЕ ВОЛОКНО А НЕ ГОТОВЫЕ ИЗДЕЛИЯ С БОЛЕЕ ВЫСОКОЙ ДОБАВЛЕННОЙ СТОИМОСТЬЮ ЧТО ГОРАЗДО ПРИБЫЛЬНЕЕ ПОЧЕМУ ОТПРАВЛЯЯ ВЫРАЩЕННЫЙ НЕЛЕГКИМ ТРУДОМ ХЛОПОК ЗА ПРЕДЕЛЫ РЕСПУБЛИКИ ТОТ ЖЕ ХЛОПКОРОБ ЗАТЕМ ВЫНУЖДЕН ПОКУПАТЬ РУБАШКУ ИЗ УЗБЕКСКОГО ХЛОПКА ЗА ГОРАЗДО БОЛЬШУЮ ЦЕНУ И ПОДОБНЫХ ВОПРОСОВ БЫЛО НЕМАЛО НАДО ОТДАТЬ ДОЛЖНОЕ НАШИМ СПЕЦИАЛИСТАМ ОНИ ПЫТАЛИСЬ ОТВЕТИТЬ НА ВСЕ ВОПРОСЫ ГОВОРИЛИ О ТОМ ЧТО В БЫВШЕМ СОЮЗЕ УЗБЕКИСТАНУ ОТВОДИЛАСЬ РОЛЬ ОСНОВНОГО ПРОИЗВОДИТЕЛЯ ХЛОПКА СЫРЦА И ПОСТАВЩИКА ХЛОПКОВОГО ВОЛОКНА ДЛЯ ДАЛЬНЕЙШЕЙ ПЕРЕРАБОТКИ В ДРУГИЕ РЕСПУБЛИКИ О ТОМ ЧТО ОБОРУДОВАНИЕ ИСПОЛЬЗУЕМОЕ НА НЕМНОГОЧИСЛЕННЫХ ТЕКСТИЛЬНЫХ ПРЕДПРИЯТИЯХ БЫЛО МОРАЛЬНО УСТАРЕВШИМ И ФИЗИЧЕСКИ ИЗНОШЕННЫМ ЧТО НЕ ПОЗВОЛЯЛО ВНЕДРЯТЬ НОВЫЕ ТЕХНОЛОГИИ И ВЫПУСКАТЬ КОНКУРЕНТОСПОСОБНУЮ ПРОДУКЦИЮ О ТОМ ЧТО ВОПРОСАМИ ЭКСПОРТА ЗАНИМАЛСЯ ЦЕНТР КОТОРЫЙ И ОПРЕДЕЛЯЛ ЧТО СКОЛЬКО И В КАКИЕ СТРАНЫ ОТПРАВЛЯТЬ А САМА РЕСПУБЛИКА НАПРЯМУЮ ОТ ЭКСПОРТА ХЛОПКОВОГО ВОЛОКНА ДОХОДОВ НЕ ПОЛУЧАЛА МОЖНО БЫЛО ПОСОЧУВСТВОВАТЬ СПЕЦИАЛИСТАМ В ЧАСТНОСТИ ИМ ХОРОШО БЫЛО ИЗВЕСТНО ЧТО РАСПОЛАГАЯ ХОРОШЕЙ СЫРЬЕВОЙ БАЗОЙ ВЫГОДНО РАЗВИВАТЬ ТЕКСТИЛЬНОЕ ПРОИЗВОДСТВО ЧТО НА ПРОИЗВОДСТВО ПРЯЖИ И ТКАНЕЙ ПРИХОДИТСЯ ОКОЛО 80 ПРОЦЕНТОВ ДОБАВЛЕННОЙ СТОИМОСТИ КОНЕЧНОЙ ТОВАРНОЙ ПРОДУКЦИИ ТОГДА КАК НА ПРОИЗВОДСТВО ХЛОПКА ВОЛОКНА ОКОЛО 10 ПРОЦЕНТОВ ТО ЕСТЬ СТРАНЫ ЭКСПОРТЕРЫ ПРЯЖИ И ТКАНЕЙ ПОЛУЧАЮТ ДОХОДЫ В ВОСЕМЬ РАЗ ПРЕВЫШАЮЩИЕ ДОХОД ОТ ЭКСПОРТА ХЛОПКОВОГО ВОЛОКНА А ЕСЛИ ЭКСПОРТИРОВАТЬ ГОТОВУЮ ОДЕЖДУ ТО ДОХОДЫ ВЫРАСТУТ ЕЩЕ БОЛЬШЕ НО В ТЕ ВРЕМЕНА И В ТЕХ УСЛОВИЯХ ОПРЕДЕЛЕННЫХ БЫВШЕЙ КОМАНДНО АДМИНИСТРАТИВНОЙ СИСТЕМОЙ РЕШЕНИЯ ПРИНИМАЛИСЬ НЕ НА МЕСТАХ В СОЮЗНЫХ РЕСПУБЛИКАХ А В ТАК НАЗЫВАЕМОМ ЦЕНТРЕ СИТУАЦИЯ КАРДИНАЛЬНО ИЗМЕНИЛАСЬ ПОСЛЕ ОБРЕТЕНИЯ УЗБЕКИСТАНОМ НЕЗАВИСИМОСТИ РАЗРАБОТКИ И НАЧАЛА РЕАЛИЗАЦИИ ЦЕЛЕНАПРАВЛЕННОЙ СИСТЕМНОЙ ГОСУДАРСТВЕННОЙ ПРОМЫШЛЕННОЙ ПОЛИТИКИ НАЦЕЛЕННОЙ НА ДИВЕРСИФИКАЦИЮ И МОДЕРНИЗАЦИЮ ПОВЫШЕНИЕ КОНКУРЕНТОСПОСОБНОСТИ ОТЕЧЕСТВЕННОЙ ЭКОНОМИКИ ПОДДЕРЖКУ РАЗВИТИЯ ВЕДУЩИХ ОТРАСЛЕЙ В ТОМ ЧИСЛЕ ПО НАРАЩИВАНИЮ ИХ ЭКСПОРТНОГО ПОТЕНЦИАЛА ЗА СЧЕТ УГЛУБЛЕНИЯ ПЕРЕРАБОТКИ МЕСТНОГО СЫРЬЯ ПОСЛЕДОВАТЕЛЬНАЯ И ПЛАНОМЕРНАЯ ПЕРЕОРИЕНТАЦИЯ ЭКСПОРТА С СЫРЬЯ НА ГОТОВУЮ ПРОДУКЦИЮ С ВЫСОКОЙ ДОБАВЛЕННОЙ СТОИМОСТЬЮ ПОЗВОЛИЛА СФОРМИРОВАТЬ НОВУЮ СТРАТЕГИЮ РАЗВИТИЯ ЛЕГКОЙ ПРОМЫШЛЕННОСТИ НАЦЕЛЕННУЮ НА ПЕРСПЕКТИВУ МОЩНЫЙ ИМПУЛЬС НОВОМУ ЭТАПУ РАЗВИТИЯ ОТРАСЛИ ПРИДАЛИ ПРИНЯТЫЕ В РАЗНЫЕ ГОДЫ РУКОВОДСТВОМ РЕСПУБЛИКИ ПРОГРАММНЫЕ'\n",
    "stemmer_en = nltk.SnowballStemmer(\"english\")\n",
    "stemmer_ru = nltk.SnowballStemmer(\"russian\")\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "\n",
    "# print([stemmer_ru.stem(word) for word in test_sen.split() if stemmer_ru.stem(word) not in stopwords.words(\"russian\") ])\n",
    "stemmed_sentence = [stemmer_ru.stem(word) for word in test_sen.split()]\n",
    "tokens = [token for token in stemmed_sentence if token not in russian_stopwords\\\n",
    "            and token.strip() not in punctuation]\n",
    "print(' '.join(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hs2cdoQu85ZO"
   },
   "outputs": [],
   "source": [
    "# Incase teacher allows lemmatizer \n",
    "# But Very slow will stick with stemmer\n",
    "# morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "# for word in test_sen.split():\n",
    "#     p = morph.parse(word)[0]\n",
    "#     print(p.normal_form, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlThpXYatF7m"
   },
   "source": [
    "## Implementation of Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLXSpIMUoNcf"
   },
   "outputs": [],
   "source": [
    "class InvertedIndexer:\n",
    "    \"\"\"\n",
    "    This class makes inverted index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename=False):\n",
    "        self.filename = filename\n",
    "        self.stemmer_ru = nltk.SnowballStemmer(\"russian\")\n",
    "        self.stopwords = set(stopwords.words(\"russian\")) | set(stopwords.words(\"english\"))\n",
    "        self.punctuation = punctuation # from string import punctuation\n",
    "        if filename:\n",
    "            self.inverted_index = self._build_index(self.filename)\n",
    "        else:\n",
    "            self.inverted_index = defaultdict(set)\n",
    "\n",
    "    def preprocess(self, sentence):\n",
    "        \"\"\"\n",
    "        Method to remove stop words and punctuations return tokens\n",
    "        \"\"\"\n",
    "        NONTEXT = re.compile('[^0-9 a-z#+_а-яё]')\n",
    "\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.translate(str.maketrans('', '', punctuation))\n",
    "        sentence = re.sub(NONTEXT,'',sentence)\n",
    "\n",
    "        # Heavy Operation Taking lot of time will move it outside\n",
    "        # tokens = [self.stemmer_ru.stem(word) for word in sentence.split()]\n",
    "\n",
    "        tokens = [token for token in sentence.split() if token not in self.stopwords]\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def stem_keys(self, inverted_index):\n",
    "        \"\"\"\n",
    "        Called after index is built to stem all the keys and normalize them\n",
    "        \"\"\"\n",
    "        logger.debug('Indexing Complete will not Stem keys and remap indexes')\n",
    "        temp_dict = defaultdict(set)\n",
    "        i = 0\n",
    "        for word in tqdm(inverted_index):\n",
    "\n",
    "            stemmed_key = self.stemmer_ru.stem(word)\n",
    "            temp_dict[stemmed_key].update(inverted_index[word])\n",
    "            inverted_index[word] = None\n",
    "\n",
    "        inverted_index = temp_dict\n",
    "        logger.debug('Done Stemmping Indexes')\n",
    "        return inverted_index\n",
    "\n",
    "    def _build_index(self, indexing_data_location):\n",
    "        \"\"\"\n",
    "        This method builds the inverted index and returns the invrted index dictionary\n",
    "        \"\"\"\n",
    "        inverted_index = defaultdict(set)\n",
    "        with gzip.open(indexing_data_location, \"rb\") as f:\n",
    "\n",
    "            for line in tqdm(f):\n",
    "                line = line.decode().split('\\t')\n",
    "                file_number = line[0]\n",
    "                subject = line[1]\n",
    "                text = line[2]\n",
    "                line = subject + ' ' + text\n",
    "\n",
    "                for word in self.preprocess(line):\n",
    "                        inverted_index[word].add(int(file_number))\n",
    "\n",
    "        # Intermediate Save\n",
    "        # with open('/content/intermediate_inverted_index.pickle', mode='wb') as f:\n",
    "        #     pickle.dump(inverted_index, f)\n",
    "        # Collab crashed don't do that \n",
    "\n",
    "        inverted_index = self.stem_keys(inverted_index)\n",
    "\n",
    "        return inverted_index\n",
    "\n",
    "    def save(self, filename_to_save):\n",
    "        \"\"\"\n",
    "        Save method to save the inverted indexes\n",
    "        \"\"\"\n",
    "        with open(filename_to_save, mode='wb') as f:\n",
    "            pickle.dump(self.inverted_index, f)\n",
    "\n",
    "    def load(self, filelocation_to_load):\n",
    "        \"\"\"\n",
    "        Load method to load the inverted indexes\n",
    "        \"\"\"\n",
    "        with open(filelocation_to_load, mode='rb') as f:\n",
    "            self.inverted_index = pickle.load(f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kas0byg7tEUx"
   },
   "outputs": [],
   "source": [
    "class SolutionPredictor:\n",
    "    \"\"\"\n",
    "    This classes uses object of Hw1SolutionIndexer\n",
    "    to make boolean search\n",
    "    \"\"\"\n",
    "    def __init__(self, indexer):\n",
    "        \"\"\"\n",
    "        indexer : object of class Hw1SolutionIndexer\n",
    "        \"\"\"\n",
    "        self.indexer = indexer\n",
    "\n",
    "\n",
    "    def find_docs(self, query):\n",
    "        \"\"\"\n",
    "        This method provides booleaen search\n",
    "        query : string with text of query\n",
    "        Returns Python set with documents which contain query words\n",
    "        Should return maximum 100 docs\n",
    "        \"\"\"\n",
    "        # Your code is here\n",
    "        tokens = self.indexer.preprocess(query)\n",
    "        tokens = [self.indexer.stemmer_ru.stem(word) for word in tokens]\n",
    "        docs_list = set()\n",
    "        for word in tokens:\n",
    "            if len(docs_list) > 0:\n",
    "                docs_list.intersection_update(self.indexer.inverted_index[word])\n",
    "            else:\n",
    "                docs_list.update(self.indexer.inverted_index[word])\n",
    "\n",
    "        return set(itertools.islice(docs_list, 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4uSOwL3XpAE"
   },
   "source": [
    "## Testing and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wG51W1lAXoM1"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "BASELINE_SCORE = 0.3\n",
    "BASELINE_TIME = 0.1\n",
    "\n",
    "\n",
    "def load_true_docs(true_docs_path):\n",
    "    \"\"\"\n",
    "    Function loads relevant docs for queries\n",
    "    \"\"\"\n",
    "    true_docs_for_q = {}\n",
    "    with open(true_docs_path) as f:\n",
    "        for line in f:\n",
    "            q, doc = line.strip().split('\\t')\n",
    "            q = int(q)\n",
    "            doc = int(doc)\n",
    "            if q not in true_docs_for_q:\n",
    "                true_docs_for_q[q] = set()\n",
    "            true_docs_for_q[q].add(doc)\n",
    "    return true_docs_for_q \n",
    "\n",
    "\n",
    "def calc_score(predictor, true_docs_for_q, queries_path):\n",
    "    \"\"\"\n",
    "    Function calcs percent of founded docs and \n",
    "    average responding time for query\n",
    "    \"\"\"\n",
    "    t0_predict = time.time()\n",
    "    num_founded_docs = 0\n",
    "    num_true_docs = 0\n",
    "    with open(queries_path) as f:\n",
    "        for query_num, line in enumerate(f):\n",
    "            q, q_text = line.strip().split('\\t')\n",
    "            q = int(q)\n",
    "            pred_docs = predictor.find_docs(q_text)\n",
    "            try:\n",
    "                assert (len(pred_docs) <= 100)\n",
    "            except AssertionError:\n",
    "                print('Error! You should predict maximum 100 documents')\n",
    "                return None, None\n",
    "            true_docs = true_docs_for_q[q]\n",
    "            founded_docs = true_docs & pred_docs\n",
    "            num_founded_docs += len(founded_docs)\n",
    "            num_true_docs += len(true_docs)\n",
    "    t1_predict = time.time() \n",
    "    return num_founded_docs / num_true_docs, (t1_predict - t0_predict) / query_num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKsuNOVCdQHU"
   },
   "source": [
    "### Creating Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9u5cxslhYpjd"
   },
   "outputs": [],
   "source": [
    "# Comment if index is created\n",
    "print ('Index is creating...')\n",
    "start = time.time()\n",
    "new_index = InvertedIndexer(indexing_data_location) \n",
    "\n",
    "end = time.time()\n",
    "print ('Index has been created and saved as inverted_index.pickle in {:.4f}s'.format(end-start))\n",
    "\n",
    "\n",
    "# Other utilities\n",
    "# new_index.save('inverted_index.pickle')\n",
    "# new_index = InvertedIndexer()\n",
    "# new_index.load('inverted_index.pickle')\n",
    "# print ('Index has been created and loaded from inverted_index.pickle in {:.4f}s'.format(end-start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ydn4g88rdSzM"
   },
   "source": [
    "### Creating Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "i0wLXHoIYXVy",
    "outputId": "34c5cfd4-84a6-4b42-91fb-bd6f7eca0b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of founded docs: 0.34725634725634724. Baseline result: 0.3\n",
      "Average time for searching: 0.0029340528306506927. Baseline result: 0.1\n"
     ]
    }
   ],
   "source": [
    "new_predictor = SolutionPredictor(new_index)\n",
    "\n",
    "# Lets check your predictor on simple russian query \n",
    "some_query = 'ПРИВЕТ МИР'\n",
    "try:\n",
    "    assert (isinstance(new_predictor.find_docs(some_query), set))\n",
    "except AssertionError:\n",
    "    print('Error! You always should return Python set')\n",
    "\n",
    "\n",
    "# Lets check your predictor on query with words which you did not see \n",
    "one_missed_word = 'ПРИВЕТ #SOMESTRANGE_WORD#'\n",
    "all_missed_words = '#SOMESTRANGE_WORD#, HAHAHA#'\n",
    "try:\n",
    "    assert (isinstance(new_predictor.find_docs(one_missed_word), set))\n",
    "    assert (isinstance(new_predictor.find_docs(all_missed_words), set))\n",
    "except AssertionError:\n",
    "    print('Error! You should return Python set even if you do not know any word in query')\n",
    "\n",
    "\n",
    "true_docs_for_q = load_true_docs(truedoc_validate)\n",
    "score, avgtime = calc_score(new_predictor, true_docs_for_q, query_validate)\n",
    "if score is None or avgtime is None:\n",
    "    print('Problem')\n",
    "\n",
    "print ('Percent of founded docs: {}. Baseline result: {}'.format(score, BASELINE_SCORE))\n",
    "print ('Average time for searching: {}. Baseline result: {}'.format(avgtime, BASELINE_TIME))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Boolean Retrieval Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
